




# FLAME 2 Wildfire Dataset

This work presents a methodology for identifying and mapping fire and smoke using high temporal 
and spatial-resolution observations from an integrated two sensor (mid-wave IR and visible bands) 
UAS-based imaging system. The paper also presents a unique dataset of side-by-side RGB/IR imagery 
collected during a prescribed fire near Flagstaff, Arizona in 2021 [20]. The images are jointly 
labeled by two human experts with fire/no-fire and smoke/no-smoke1 labels. In additional to aerial 
images, data on weather information, and georeferenced pre-burn point cloud data points are included 
in the dataset. It is expected that the methods developed to produce the FLAME2 dataset and others 
to follow can facilitate fire detection and modeling, as well as fire management.

![Sample of Dataset](../images/FLAME2/flame.jpg)
<!-- ![Flame detection](../images/FLAME2/flame_test.jpg) -->
<img src="../images/FLAME2/flame_test.jpg" width="300px">

More information, please reference our paper:<a href="https://ieeexplore.ieee.org/abstract/document/9953997/">FLAME 2</a>


# DH-GAN: A Physics-driven Untrained Generative Adversarial Network for 3D Microscopic Imaging using Digital Holography

In this work, we propose a new DL architecture based on generative adversarial networks that uses
a discriminative network for realizing a semantic measure for reconstruction quality while using
a generative network as a function approximator to model the inverse of hologram formation. We
impose smoothness on the background part of the recovered image using a progressive masking
module powered by simulated annealing to enhance the reconstruction quality. The proposed method
is one of its kind that exhibits high transferability to similar samples, which facilitates its fast
deployment in time-sensitive applications without the need for retraining the network

![Experiment Setup](../images/DH/DH_lab_1.png)
![Onion Epidermis - Phase information plot in 3D space](../images/DH/phase_to_3D.png)


More information, please reference our paper:<a href="https://arxiv.org/abs/2205.12920">DH-GAN</a>




# DH-GAN: A Physics-driven Untrained Generative Adversarial Network for 3D Microscopic Imaging using Digital Holography

In this work, we propose a new DL architecture based on generative adversarial networks that uses
a discriminative network for realizing a semantic measure for reconstruction quality while using
a generative network as a function approximator to model the inverse of hologram formation. We
impose smoothness on the background part of the recovered image using a progressive masking
module powered by simulated annealing to enhance the reconstruction quality. The proposed method
is one of its kind that exhibits high transferability to similar samples, which facilitates its fast
deployment in time-sensitive applications without the need for retraining the network

![Experiment Setup](../images/DH/DH_lab_1.png)
![Onion Epidermis - Phase information plot in 3D space](../images/DH/phase_to_3D.png)


More information, please reference our paper:<a href="https://arxiv.org/abs/2205.12920">DH-GAN</a>


# Deep learning serves traffic safety analysis: A forward-looking review


This paper explores deep learning (DL) methods that are used or have the potential to be used for 
traffic video analysis, emphasising driving safety for both autonomous vehicles and human-operated 
vehicles. A typical processing pipeline is presented, which can be used to understand and interpret
traffic videos by extracting operational safety metrics and providing general hints and guidelines 
to improve traffic safety. This processing framework includes several steps, including video 
enhancement, video stabilisation, semantic and incident segmentation, object detection and 
classification, trajectory extraction, speed estimation, event analysis, modelling, and anomaly 
detection. The main goal is to guide traffic analysts to develop their own custom-built processing 
frameworks by selecting the best choices for each step and offering new designs for the lacking 
modules by providing a comparative analysis of the most successful conventional and DL-based 
algorithms proposed for each step.


More information, please reference our paper:<a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/itr2.12257">Deep Learning-TSA</a>

















